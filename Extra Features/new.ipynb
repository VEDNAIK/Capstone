{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                TranslatedRecipeName  \\\n",
      "0               Chicken In Tomato Onion Gravy Recipe   \n",
      "1                      Cheese Masala Omelette Recipe   \n",
      "2  Thai Style Kai Jeow Moo Sab Recipe - Omelette ...   \n",
      "3  Chicken Dimsums Recipe - Steamed Chicken Dumpl...   \n",
      "4  Akuri Recipe (Parsi Style Seasoned Scrambled E...   \n",
      "5                        Crispy Crab Rangoons Recipe   \n",
      "6                  Japanese Chicken Udon Soup Recipe   \n",
      "7  Mexican Breakfast Tortilla, Fried Eggs & Black...   \n",
      "8  Mexican Chicken Burger Recipe With Sour Cream ...   \n",
      "9                        Chicken And Egg Soup Recipe   \n",
      "\n",
      "                               TranslatedIngredients  TotalTimeInMins  \\\n",
      "0  2 Green Chillies,2 teaspoons Ginger Garlic Pas...               30   \n",
      "1  Salt - as required,2 tablespoons Cheese - grat...               25   \n",
      "2  Sunflower Oil - for frying,4 Whole Eggs,Salt -...               20   \n",
      "3  1 cup All Purpose Flour (Maida),1/2 tablespoon...               40   \n",
      "4  3 tablespoon Fresh cream,6 Whole Eggs,Coriande...               30   \n",
      "5  Sunflower Oil - for deep frying,1/2 teaspoon C...               80   \n",
      "6  4 Button mushrooms - sliced,1/2 cup Cabbage (P...               50   \n",
      "7  3 Tortillas,1 cup Refried beans,3 tablespoons ...               25   \n",
      "8  2 tablespoons Butter - to spread,1 teaspoon Cu...               30   \n",
      "9  1/2 cup Button mushrooms - sliced,1 Carrot (Ga...               40   \n",
      "\n",
      "         Cuisine                             TranslatedInstructions  \\\n",
      "0         Indian  To begin making Chicken In Tomato Onion Gravy ...   \n",
      "1         Indian  To begin making the Cheese Masala Omelette Rec...   \n",
      "2           Thai  To begin making the Thai Style Kai Jeow Moo Sa...   \n",
      "3          Asian  To begin making the Chicken Dimsums recipe,Now...   \n",
      "4  Parsi Recipes  To begin making the Akuri Recipe, first chop o...   \n",
      "5   Indo Chinese  To begin making the Crispy Crab Rangoons, mix ...   \n",
      "6       Japanese  To begin making the Japanese Chicken Udon Soup...   \n",
      "7        Mexican  To begin making the Mexican Breakfast Tortilla...   \n",
      "8        Mexican  To begin making the Mexican Chicken Burger Rec...   \n",
      "9        Chinese  To begin making the Chicken and Noodle Soup Re...   \n",
      "\n",
      "                                                 URL  \\\n",
      "0  https://www.archanaskitchen.com/chicken-in-tom...   \n",
      "1  https://www.archanaskitchen.com/cheese-masala-...   \n",
      "2  https://www.archanaskitchen.com/thai-style-kai...   \n",
      "3  https://www.archanaskitchen.com/chicken-dimsum...   \n",
      "4  https://www.archanaskitchen.com/akuri-recipe-p...   \n",
      "5  https://www.archanaskitchen.com/crispy-crab-ra...   \n",
      "6  https://www.archanaskitchen.com/japanese-chick...   \n",
      "7  https://www.archanaskitchen.com/mexican-breakf...   \n",
      "8  https://www.archanaskitchen.com/mexican-chicke...   \n",
      "9  https://www.archanaskitchen.com/chicken-and-eg...   \n",
      "\n",
      "                                         ingredients  \\\n",
      "0  ['tomato', 'salt', 'coriander  leaves', 'chick...   \n",
      "1  ['tomato', 'cheese', 'salt', 'coriander  leave...   \n",
      "2  ['stalk spring onion ', 'salt season', 'soy sa...   \n",
      "3  ['salt', 'cloves garlic', 'soy sauce', 'spring...   \n",
      "4  ['tomato', 'salt', 'coriander  leaves', 'clove...   \n",
      "5  ['cheese', 'ginger', 'britannia', 'soy sauce',...   \n",
      "6  ['salt', 'ginger', 'boneless chicken', 'chicke...   \n",
      "7  ['re beans', 'sour', 'sunflower oil eggs', 'gu...   \n",
      "8  ['cheese', 'salt', 'burger buns', 'cumin powde...   \n",
      "9  ['salt', 'eggs', 'leek', 'chicken stock', 'car...   \n",
      "\n",
      "                                           image-url  Ingredient-count  \\\n",
      "0  https://www.archanaskitchen.com/images/archana...                11   \n",
      "1  https://www.archanaskitchen.com/images/archana...                 8   \n",
      "2  https://www.archanaskitchen.com/images/archana...                 6   \n",
      "3  https://www.archanaskitchen.com/images/archana...                 7   \n",
      "4  https://www.archanaskitchen.com/images/archana...                 8   \n",
      "5  https://www.archanaskitchen.com/images/archana...                10   \n",
      "6  https://www.archanaskitchen.com/images/archana...                12   \n",
      "7  https://www.archanaskitchen.com/images/archana...                 7   \n",
      "8  https://www.archanaskitchen.com/images/archana...                14   \n",
      "9  https://www.archanaskitchen.com/images/archana...                11   \n",
      "\n",
      "                                              parsed  \n",
      "0  tomato, salt, coriander leaf, chicken masala, ...  \n",
      "1  tomato, cheese, salt, coriander leaf, onion, e...  \n",
      "2  stalk spring onion, salt season, soy sauce, ch...  \n",
      "3  salt, clove garlic, soy sauce, spring onion, c...  \n",
      "4  tomato, salt, coriander leaf, clove garlic, on...  \n",
      "5  cheese, ginger, britannia, soy sauce, carrot, ...  \n",
      "6  salt, ginger, boneless chicken, chicken stock,...  \n",
      "7  bean, sour, sunflower oil egg, guacamole, toma...  \n",
      "8  cheese, salt, burger bun, cumin powder, sour, ...  \n",
      "9  salt, egg, leek, chicken stock, carrot, white ...  \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "#from input_cleaner import ingredient_parser, get_and_sort_corpus\n",
    "# Load the SentenceTransformer model\n",
    "bert = SentenceTransformer('bert-base-nli-mean-tokens')\n",
    " \n",
    "# Load the DataFrame from CSV\n",
    "df = pd.read_csv('/Users/ved/Desktop/Capstone/Dataset/string_ingredients.csv')\n",
    " \n",
    "# Load precomputed sentence embeddings\n",
    "sentence_embeddings = np.load('sentence_embeddings.npy')\n",
    " \n",
    "def custom(input_str):\n",
    "    try:\n",
    "        # Encode the input string using BERT\n",
    "        input_str = input_str.split(\",\")\n",
    "    # parse ingredient list\n",
    "        input_str = ingredient_parser(input_str)\n",
    "        input_str = get_and_sort_corpus(input_str)\n",
    "        input_str = \", \".join(input_str)\n",
    "        input_embedding = bert.encode(input_str)\n",
    " \n",
    "        # Compute cosine similarities between the input and all recipes\n",
    "        similarities = cosine_similarity(sentence_embeddings, input_embedding.reshape(1, -1))\n",
    " \n",
    "        # Get the indices of the top 10 most similar recipes\n",
    "        top_indices = similarities.argsort(axis=0)[-10:][::-1].flatten()\n",
    " \n",
    "        # Create a DataFrame with the recommended recipes\n",
    "        recommendation_data = df.iloc[top_indices]\n",
    "        recommendation_data = recommendation_data.reset_index(drop=True)\n",
    "        return recommendation_data\n",
    "    except Exception as e:\n",
    "        return f\"An error occurred: {str(e)}\"\n",
    " \n",
    "# Example input\n",
    "input_str = \"chicken, eggs , tomato, onion\"\n",
    "result = custom(input_str)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "import string \n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "#nltk.download('wordnet')\n",
    "\n",
    "import unidecode\n",
    "import nltk.corpus\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from collections import defaultdict\n",
    "import config\n",
    "\n",
    "def ingredient_parser(ingredients):\n",
    "    # measures and common words (already lemmatized)   \n",
    "    measures = ['teaspoon', 't', 'tsp.', 'tablespoon', 'T', ...]\n",
    "    words_to_remove = ['fresh', 'a', 'red', 'bunch', ...]\n",
    "    # Turn ingredient list from string into a list \n",
    "    if isinstance(ingredients, list):\n",
    "       pass\n",
    "    else:\n",
    "       ingredients = ast.literal_eval(ingredients)\n",
    "    # We first get rid of all the punctuation\n",
    "    remove_punctuations = str.maketrans('', '', string.punctuation)\n",
    "    # initialize nltk's lemmatizer    \n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    ingred_list = []\n",
    "    for each_item in ingredients:\n",
    "        each_item.translate(remove_punctuations)\n",
    "        # We split up with hyphens as well as spaces\n",
    "        items = re.split(' |-', each_item)\n",
    "        # Get rid of words containing non alphabet letters\n",
    "        items = [word for word in items if word.isalpha()]\n",
    "        # Turn everything to lowercase\n",
    "        items = [word.lower() for word in items]\n",
    "        # remove accents\n",
    "        items = [unidecode.unidecode(word) for word in items]\n",
    "        # Lemmatize words so we can compare words to measuring words\n",
    "        items = [lemmatizer.lemmatize(word) for word in items]\n",
    "        # get rid of stop words\n",
    "        stop_words = set(nltk.corpus.stopwords.words('english'))\n",
    "        items = [word for word in items if word not in stop_words]\n",
    "        # Gets rid of measuring words/phrases, e.g. heaped teaspoon\n",
    "        items = [word for word in items if word not in measures]\n",
    "        # Get rid of common easy words\n",
    "        items = [word for word in items if word not in words_to_remove]\n",
    "        if items:\n",
    "           ingred_list.append(' '.join(items))\n",
    "    return ingred_list\n",
    "\n",
    "# get corpus with the documents sorted in alphabetical order\n",
    "def get_and_sort_corpus(data):\n",
    "    data.sort()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "122"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(actual_recipes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                 Chicken In Tomato Onion Gravy Recipe\n",
       "1    Chicken Dimsums Recipe - Steamed Chicken Dumpl...\n",
       "2    Thai Style Kai Jeow Moo Sab Recipe - Omelette ...\n",
       "3                        Cheese Masala Omelette Recipe\n",
       "4    Akuri Recipe (Parsi Style Seasoned Scrambled E...\n",
       "5                    Japanese Chicken Udon Soup Recipe\n",
       "6    Mexican Breakfast Tortilla, Fried Eggs & Black...\n",
       "7    Mexican Chicken Burger Recipe With Sour Cream ...\n",
       "8                          Crispy Crab Rangoons Recipe\n",
       "9                          Chicken And Egg Soup Recipe\n",
       "Name: TranslatedRecipeName, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['TranslatedRecipeName']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[True, True]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision at 10 using Word2Vec using TF-IDF vectorization: 0.2\n"
     ]
    }
   ],
   "source": [
    "K = 10 # mention it as actual no. of recipies\n",
    "# Calculate P@K\n",
    "correct_recommendations=[]\n",
    "for recipe in actual_recipes:\n",
    "    for i in result['TranslatedRecipeName'][:K]:\n",
    "        if recipe == i:\n",
    "            correct_recommendations.append(True)\n",
    "#correct_recommendations = [recipe in rec['TranslatedRecipeName'][:K] for recipe in actual_recipes]\n",
    "precision_at_K = sum(correct_recommendations) / K\n",
    "print(f\"Precision at {K} using Word2Vec using TF-IDF vectorization: {precision_at_K}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading wordnet: <urlopen error [Errno 60] Operation\n",
      "[nltk_data]     timed out>\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "import ast\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "import string \n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "\n",
    "import unidecode\n",
    "import nltk.corpus\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from collections import defaultdict\n",
    "import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Dataset/Cleaned_Indian_Food_Dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/1m/v10vjxqd235fn30s91s6nnx40000gn/T/ipykernel_30107/1364071601.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"ingredients\"][i]=re.sub(\"\\(.*?\\)\",\"\",df[\"ingredients\"][i])\n",
      "/var/folders/1m/v10vjxqd235fn30s91s6nnx40000gn/T/ipykernel_30107/1364071601.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"ingredients\"][i] = df[\"ingredients\"][i].replace('(','').replace(')','')\n",
      "/var/folders/1m/v10vjxqd235fn30s91s6nnx40000gn/T/ipykernel_30107/1364071601.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"ingredients\"][i] = df[\"ingredients\"][i].split(',')\n"
     ]
    }
   ],
   "source": [
    "df.rename(columns = {'Cleaned-Ingredients':'ingredients'}, inplace = True)\n",
    "for i in range(len(df[\"ingredients\"])):\n",
    "    df[\"ingredients\"][i]=re.sub(\"\\(.*?\\)\",\"\",df[\"ingredients\"][i])\n",
    "    df[\"ingredients\"][i] = df[\"ingredients\"][i].replace('(','').replace(')','')\n",
    "    df[\"ingredients\"][i] = df[\"ingredients\"][i].split(',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ingredient_parser(ingredients):\n",
    "    # measures and common words (already lemmatized)   \n",
    "    measures = ['teaspoon', 't', 'tsp.', 'tablespoon', 'T', ...]\n",
    "    words_to_remove = ['fresh', 'a', 'red', 'bunch', ...]\n",
    "    # Turn ingredient list from string into a list \n",
    "    if isinstance(ingredients, list):\n",
    "       pass\n",
    "    else:\n",
    "       ingredients = ast.literal_eval(ingredients)\n",
    "    # We first get rid of all the punctuation\n",
    "    remove_punctuations = str.maketrans('', '', string.punctuation)\n",
    "    # initialize nltk's lemmatizer    \n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    ingred_list = []\n",
    "    for each_item in ingredients:\n",
    "        each_item.translate(remove_punctuations)\n",
    "        # We split up with hyphens as well as spaces\n",
    "        items = re.split(' |-', each_item)\n",
    "        # Get rid of words containing non alphabet letters\n",
    "        items = [word for word in items if word.isalpha()]\n",
    "        # Turn everything to lowercase\n",
    "        items = [word.lower() for word in items]\n",
    "        # remove accents\n",
    "        items = [unidecode.unidecode(word) for word in items]\n",
    "        # Lemmatize words so we can compare words to measuring words\n",
    "        items = [lemmatizer.lemmatize(word) for word in items]\n",
    "        # get rid of stop words\n",
    "        stop_words = set(nltk.corpus.stopwords.words('english'))\n",
    "        items = [word for word in items if word not in stop_words]\n",
    "        # Gets rid of measuring words/phrases, e.g. heaped teaspoon\n",
    "        items = [word for word in items if word not in measures]\n",
    "        # Get rid of common easy words\n",
    "        items = [word for word in items if word not in words_to_remove]\n",
    "        if items:\n",
    "           ingred_list.append(' '.join(items))\n",
    "    return ingred_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['parsed'] = df.ingredients.apply(ingredient_parser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['parsed'] = df['parsed'].apply(lambda x: ', '.join(map(str, x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('string_ingredients.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
